# ğŸ™ï¸ Audio Emotion Recognition (SVM vs CNN)

This project compares two machine learning models â€” **Support Vector Machine (SVM)** and **Convolutional Neural Network (CNN)** â€” for recognizing emotions from speech audio files. It uses the **RAVDESS** dataset and includes a user-friendly interface built with **Streamlit**.

## ğŸ“Œ Features
![Streaming App UI](prediction.jpg)
- Emotion detection from speech (e.g., happy, sad, angry, etc.)
- Audio preprocessing and feature extraction (MFCC, Chroma, etc.)
- SVM model using handcrafted features
- CNN model trained on MFCC spectrograms
- Streamlit app for real-time testing

## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ app/ # Streamlit interface

â”œâ”€â”€ data/ # Audio files (RAVDESS)

â”œâ”€â”€ models/ # Saved models (SVM .pkl & CNN .h5)

â”œâ”€â”€ notebooks/ # Jupyter notebooks for training

â”œâ”€â”€ requirements.txt # Python dependencies

â””â”€â”€ README.md



## â–¶ï¸ How to Run

1. Clone the repo:
   ```bash
   git clone https://github.com/laggywiggl/audio-emotion-recognition.git
   cd audio-emotion-recognition
2. Install requirements:
   ```bash
   pip install -r requirements.txt
4. Launch the app:
   ```bash
   streamlit run app.py
   
Upload a .wav file and get emotion predictions from both models!

## ğŸ“Š Results (Accuracy)
Model	Accuracy
SVM	97%
CNN	94%
